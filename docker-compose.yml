# FlowLens Docker Compose - Minimal Configuration
# PostgreSQL only, suitable for <10k flows/sec
# Generated from System Settings on 2026-01-08 22:14:38

# Shared environment variable definitions
x-db-env: &db-env
  POSTGRES_HOST: postgres
  POSTGRES_PORT: 5432
  POSTGRES_USER: flowlens
  POSTGRES_PASSWORD: flowlens
  POSTGRES_DATABASE: flowlens

x-logging-env: &logging-env
  LOG_LEVEL: INFO
  LOG_FORMAT: json

x-classification-env: &classification-env
  CLASSIFICATION_WORKER_COUNT: "1"
  CLASSIFICATION_POLL_INTERVAL_MS: "30000"
  CLASSIFICATION_AUTO_UPDATE_CONFIDENCE_THRESHOLD: "0.7"
  CLASSIFICATION_MIN_OBSERVATION_HOURS: "1"
  CLASSIFICATION_MIN_FLOWS_REQUIRED: "100"
  CLASSIFICATION_BATCH_SIZE: "100"
  CLASSIFICATION_HIGH_CONFIDENCE_THRESHOLD: "0.85"
  CLASSIFICATION_RECLASSIFY_INTERVAL_HOURS: "24"

# Combined environments for services that need multiple anchors
x-db-logging-env: &db-logging-env
  POSTGRES_HOST: postgres
  POSTGRES_PORT: 5432
  POSTGRES_USER: flowlens
  POSTGRES_PASSWORD: flowlens
  POSTGRES_DATABASE: flowlens
  LOG_LEVEL: INFO
  LOG_FORMAT: json

x-classification-full-env: &classification-full-env
  POSTGRES_HOST: postgres
  POSTGRES_PORT: 5432
  POSTGRES_USER: flowlens
  POSTGRES_PASSWORD: flowlens
  POSTGRES_DATABASE: flowlens
  CLASSIFICATION_WORKER_COUNT: "1"
  CLASSIFICATION_POLL_INTERVAL_MS: "30000"
  CLASSIFICATION_AUTO_UPDATE_CONFIDENCE_THRESHOLD: "0.7"
  CLASSIFICATION_MIN_OBSERVATION_HOURS: "1"
  CLASSIFICATION_MIN_FLOWS_REQUIRED: "100"
  CLASSIFICATION_BATCH_SIZE: "100"
  CLASSIFICATION_HIGH_CONFIDENCE_THRESHOLD: "0.85"
  CLASSIFICATION_RECLASSIFY_INTERVAL_HOURS: "24"
  LOG_LEVEL: INFO
  LOG_FORMAT: json

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: flowlens-postgres
    environment:
      POSTGRES_USER: flowlens
      POSTGRES_PASSWORD: flowlens
      POSTGRES_DB: flowlens
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U flowlens"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Database migrations
  migrations:
    build:
      context: .
      target: production
    container_name: flowlens-migrations
    command: ["alembic", "upgrade", "head"]
    environment:
      <<: *db-env
    depends_on:
      postgres:
        condition: service_healthy

  # API Service
  api:
    build:
      context: .
      target: production
    container_name: flowlens-api
    command: ["python", "-m", "flowlens.api.main"]
    environment:
      ENVIRONMENT: development
      DEBUG: "true"
      <<: *db-env
      API_HOST: "0.0.0.0"
      API_PORT: "8000"
      API_WORKERS: "2"
      API_CORS_ORIGINS: "*"
      AUTH_ENABLED: "true"
      AUTH_SECRET_KEY: "change-me-in-production"
      CLASSIFICATION_MIN_OBSERVATION_HOURS: "1"
      CLASSIFICATION_MIN_FLOWS_REQUIRED: "100"
      LOG_LEVEL: INFO
      LOG_FORMAT: json
      # AI/LLM Configuration - LM Studio with IBM Granite
      LLM_PROVIDER: "openai_compatible"
      LLM_BASE_URL: "http://10.100.192.189:1234/v1"
      LLM_MODEL: "ibm/granite-3.2-8b"
      LLM_TEMPERATURE: "0.7"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    ports:
      - "8000:8000"
    depends_on:
      migrations:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; httpx.get('http://localhost:8000/admin/health/live')"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Flow Ingestion Service
  ingestion:
    build:
      context: .
      target: production
    container_name: flowlens-ingestion
    command: ["python", "-m", "flowlens.ingestion.main"]
    environment:
      ENVIRONMENT: development
      <<: *db-env
      INGESTION_BIND_ADDRESS: "0.0.0.0"
      INGESTION_NETFLOW_PORT: "2055"
      INGESTION_SFLOW_PORT: "6343"
      INGESTION_BATCH_SIZE: "1000"
      INGESTION_BATCH_TIMEOUT_MS: "1000"
      INGESTION_QUEUE_MAX_SIZE: "100000"
      INGESTION_SAMPLE_THRESHOLD: "50000"
      INGESTION_DROP_THRESHOLD: "80000"
      INGESTION_SAMPLE_RATE: "10"
      LOG_LEVEL: INFO
      LOG_FORMAT: json
    ports:
      - "2055:2055/udp"
      - "6343:6343/udp"
    depends_on:
      migrations:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "pgrep", "-f", "flowlens.ingestion.main"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Enrichment Service (enriches flow records with DNS, GeoIP, etc.)
  enrichment:
    build:
      context: .
      target: production
    container_name: flowlens-enrichment
    command: ["python", "-m", "flowlens.enrichment.main"]
    environment:
      ENVIRONMENT: development
      <<: *db-logging-env
      ENRICHMENT_WORKER_COUNT: "4"
      ENRICHMENT_BATCH_SIZE: "500"
      ENRICHMENT_POLL_INTERVAL_MS: "100"
      ENRICHMENT_DNS_TIMEOUT: "2.0"
      ENRICHMENT_DNS_CACHE_TTL: "3600"
      ENRICHMENT_DNS_CACHE_SIZE: "10000"
    depends_on:
      migrations:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "pgrep", "-f", "flowlens.enrichment.main"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Resolution Service (builds assets and dependencies from flows)
  resolution:
    build:
      context: .
      target: production
    container_name: flowlens-resolution
    command: ["python", "-m", "flowlens.resolution.main"]
    env_file:
      - .env
    environment:
      ENVIRONMENT: development
      <<: *db-logging-env
      RESOLUTION_WORKER_COUNT: "1"
      RESOLUTION_WINDOW_SIZE_MINUTES: "5"
      RESOLUTION_BATCH_SIZE: "1000"
      RESOLUTION_POLL_INTERVAL_MS: "500"
      RESOLUTION_STALE_THRESHOLD_HOURS: "24"
      RESOLUTION_EXCLUDE_EXTERNAL_IPS: "false"
      RESOLUTION_EXCLUDE_EXTERNAL_SOURCES: "false"
      RESOLUTION_EXCLUDE_EXTERNAL_TARGETS: "false"
    depends_on:
      migrations:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "pgrep", "-f", "flowlens.resolution.main"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Classification Service (auto-classifies assets based on behavioral features)
  classification:
    build:
      context: .
      target: production
    container_name: flowlens-classification
    command: ["python", "-m", "flowlens.classification.main"]
    environment:
      ENVIRONMENT: development
      <<: *classification-full-env
    depends_on:
      migrations:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "pgrep", "-f", "flowlens.classification.main"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Frontend UI
  frontend:
    build:
      context: ./frontend
      target: production
    container_name: flowlens-frontend
    ports:
      - "3000:80"
    depends_on:
      - api
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

volumes:
  postgres_data:

networks:
  default:
    name: flowlens-network